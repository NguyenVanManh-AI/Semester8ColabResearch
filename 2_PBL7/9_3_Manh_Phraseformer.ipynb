{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4","authorship_tag":"ABX9TyPslp3KGwKasex2P5uS3OrS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Import toolkit\n"],"metadata":{"id":"REgymOKeIeBN"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"0FML0WbkIn6B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717167167437,"user_tz":-420,"elapsed":18873,"user":{"displayName":"Mạnh Nguyễn Văn","userId":"02551429762945734525"}},"outputId":"2d9081e8-f74c-43ca-f82f-aba057d656b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lwquoLEqHtAe"},"outputs":[],"source":["import os\n","os.chdir(\"/content/drive/MyDrive/2_PBL7/\")"]},{"cell_type":"code","source":["!pip install torch transformers networkx node2vec"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nvfB35vIItRV","executionInfo":{"status":"ok","timestamp":1717167247332,"user_tz":-420,"elapsed":76161,"user":{"displayName":"Mạnh Nguyễn Văn","userId":"02551429762945734525"}},"outputId":"f1938688-f3c5-4ad9-ff63-0289ad8e7255"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n","Collecting node2vec\n","  Downloading node2vec-0.4.6-py3-none-any.whl (7.0 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: gensim<5.0.0,>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from node2vec) (4.3.2)\n","Requirement already satisfied: joblib<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from node2vec) (1.4.2)\n","Collecting networkx\n","  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.1.2->node2vec) (1.11.4)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.1.2->node2vec) (6.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, node2vec\n","  Attempting uninstall: networkx\n","    Found existing installation: networkx 3.3\n","    Uninstalling networkx-3.3:\n","      Successfully uninstalled networkx-3.3\n","Successfully installed networkx-2.8.8 node2vec-0.4.6 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertModel\n","import networkx as nx\n","from node2vec import Node2Vec\n","import numpy as np\n","from torch.utils.data import DataLoader, Dataset\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn.utils.rnn import pad_sequence\n","\n","# Load BERT model and tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","bert_model = BertModel.from_pretrained('bert-base-uncased')\n","\n","# Dummy dataset class\n","class KeyphraseDataset(Dataset):\n","    def __init__(self, texts, labels):\n","        self.texts = texts\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        label = self.labels[idx]\n","        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n","        inputs['labels'] = torch.tensor(label)\n","        return inputs\n","\n","# Example data\n","texts = [\"This is a sample document.\", \"Another document for keyphrase extraction.\"]\n","labels = [[0, 0, 0, 1, 0], [0, 0, 0, 1, 1]]  # B-keyphrase: 1, I-keyphrase: 1, O: 0\n","\n","dataset = KeyphraseDataset(texts, labels)\n","\n","def collate_fn(batch):\n","    input_ids = pad_sequence([item['input_ids'].squeeze(0) for item in batch], batch_first=True, padding_value=tokenizer.pad_token_id)\n","    attention_mask = pad_sequence([item['attention_mask'].squeeze(0) for item in batch], batch_first=True, padding_value=0)\n","    labels = pad_sequence([item['labels'] for item in batch], batch_first=True, padding_value=-100)\n","    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n","\n","dataloader = DataLoader(dataset, batch_size=2, collate_fn=collate_fn)\n","\n","# Define the model\n","class Phraseformer(nn.Module):\n","    def __init__(self, bert_model, graph_embedding_dim, num_labels):\n","        super(Phraseformer, self).__init__()\n","        self.bert = bert_model\n","        self.graph_embedding_dim = graph_embedding_dim\n","        self.num_labels = num_labels\n","        self.fc = nn.Linear(bert_model.config.hidden_size + graph_embedding_dim, num_labels)\n","\n","    def forward(self, input_ids, attention_mask, graph_embeddings):\n","        outputs = self.bert(input_ids, attention_mask=attention_mask)\n","        sequence_output = outputs.last_hidden_state\n","        combined = torch.cat((sequence_output, graph_embeddings), dim=-1)\n","        logits = self.fc(combined)\n","        return logits\n","\n","# Initialize the model\n","model = Phraseformer(bert_model, graph_embedding_dim=128, num_labels=2)\n","\n","# Define loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-5)\n","\n","# Training loop\n","for epoch in range(10):  # Number of epochs\n","    for batch in dataloader:\n","        inputs = batch\n","        input_ids = inputs['input_ids']\n","        attention_mask = inputs['attention_mask']\n","        labels = inputs['labels']\n","\n","        # Dummy graph embeddings (should be computed based on your graph)\n","        batch_size, seq_len = input_ids.size()\n","        graph_embeddings = torch.randn(batch_size, seq_len, 128)\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids, attention_mask, graph_embeddings)\n","\n","        # Compute loss, ignoring the padding tokens\n","        active_loss = attention_mask.view(-1) == 1\n","        active_logits = torch.masked_select(outputs.view(-1, model.num_labels), active_loss.unsqueeze(-1)).view(-1, model.num_labels)\n","        active_labels = torch.masked_select(labels.view(-1), active_loss)\n","\n","        loss = criterion(active_logits, active_labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n","\n","print(\"Training complete\")\n"],"metadata":{"id":"9NmCnWBTKUFW","executionInfo":{"status":"error","timestamp":1717167542850,"user_tz":-420,"elapsed":1318,"user":{"displayName":"Mạnh Nguyễn Văn","userId":"02551429762945734525"}},"outputId":"03780e76-7a53-4769-b8ee-0691ae231443","colab":{"base_uri":"https://localhost:8080/","height":237}},"execution_count":8,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"The size of tensor a (20) must match the size of tensor b (10) at non-singleton dimension 0","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-60c00a20449c>\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mactive_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mactive_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mactive_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (20) must match the size of tensor b (10) at non-singleton dimension 0"]}]}]}